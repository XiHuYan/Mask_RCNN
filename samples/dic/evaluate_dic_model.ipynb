{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from os.path import join\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import keras.backend as K\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "from samples.dic import dic\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "DEVICE = \"/cpu:0\"  # /cpu:0 or /gpu:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        40\n",
      "DETECTION_MIN_CONFIDENCE       0.9\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  512\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              crop\n",
      "IMAGE_SHAPE                    [512 512   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.0001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               20\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           dic\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    128\n",
      "STEPS_PER_EPOCH                100\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           256\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = dic.DicConfig()\n",
    "class InferenceConfig(config.__class__):\n",
    "    # Run detection on one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'dic'\n",
    "\n",
    "MODEL_DIR = \"G:/DataForDL/logs/mrcnn/choosed/{}\".format(dataset_name)\n",
    "DIC_WEIGHTS_PATH = join(MODEL_DIR, 'mask_rcnn_{}_0040.h5'.format(dataset_name))  # TODO: update this path\n",
    "\n",
    "DIC_DIR = os.path.join(ROOT_DIR, \"datasets/dic_sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: 10\n",
      "Classes: ['BG', 'dic']\n"
     ]
    }
   ],
   "source": [
    "dataset = dic.DicDataset()\n",
    "dataset.load_dic(DIC_DIR, \"val\")\n",
    "\n",
    "# Must call before using the dataset\n",
    "dataset.prepare()\n",
    "\n",
    "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in inference mode\n",
    "with tf.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "model.load_weights(DIC_WEIGHTS_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def miou(y_true, y_pred):\n",
    "    label = tf.reshape(y_true, y_true.shape)\n",
    "    pred = tf.reshape(y_pred, y_pred.shape)\n",
    "\n",
    "    iou_op = tf.metrics.mean_iou(label, pred ,2)\n",
    "    with tf.Session() as sess:\n",
    "    # sess.run(tf.global_variables_initializer()) \n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "\n",
    "        sess.run(iou_op)\n",
    "        mean_iou, conf_mat = sess.run(iou_op)\n",
    "        return mean_iou\n",
    "\n",
    "\n",
    "def clip2one(masks):\n",
    "    mask = masks.sum(axis=-1)\n",
    "    return np.where(mask==0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 images\n",
      "image                    shape: (512, 512, 3)         min:   37.00000  max:  250.00000  uint8\n",
      "molded_images            shape: (1, 512, 512, 3)      min:  -86.70000  max:  146.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max:  512.00000  int32\n",
      "anchors                  shape: (1, 65472, 4)         min:   -0.17712  max:    1.05188  float32\n"
     ]
    }
   ],
   "source": [
    "# Load and display random samples\n",
    "Miou = []\n",
    "for image_id in dataset.image_ids:\n",
    "    image = dataset.load_image(image_id)\n",
    "    mask, class_ids = dataset.load_mask(image_id)\n",
    "    # visualize.display_top_masks(image, mask, class_ids, dataset.class_names)\n",
    "    # print(image.shape, mask.shape)\n",
    "    pred = model.detect([image], verbose=1)[0]['masks']\n",
    "    t, p = clip2one(mask), clip2one(pred)\n",
    "    # print(t.max(), t.shape, p.max(), p.shape)\n",
    "    Miou.append(miou(t, p))\n",
    "print(np.mean(Miou))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d4cd739e48>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(p, cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
